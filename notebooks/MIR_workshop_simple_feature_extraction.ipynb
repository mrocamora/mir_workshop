{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xkRluDRnDCC"
   },
   "source": [
    "# <center> MUSIC INFORMATION RETRIEVAL</center>\n",
    "## <center>Simple Feature Extraction</center>      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I3KK9JAunDCJ"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Byrh9EoKnDCM"
   },
   "source": [
    "### About this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twWyPxETnDCT"
   },
   "source": [
    "We will explore feature extraction for sound classification using a simple example. For sound classification, features are computed directly from audio. Ideally, good features clearly separate your classes. However, multiple instances from the same class will still have a variety (e.g. play different pitches, at different loudness, an recorded in different conditions). We need to find features that are invariant to the characteristics that do not help distinguish between classes. For example, if we want to classify instruments by timbre, we will want features that distinguish sounds by their timbre and not their pitch.\n",
    "\n",
    "**Note**: *this notebook is loosely based on a similar notebook available in [musicinformationretrieval.com](https://musicinformationretrieval.com/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aen-teg1nDCV"
   },
   "source": [
    "### How to run the notebook\n",
    "You can download the notebook and run it locally in your computer.\n",
    "\n",
    "You can also run it in Google Colab by using the following link.\n",
    "\n",
    "<table align=\"center\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/mrocamora/mir_workshop/blob/main/notebooks/MIR_workshop_simple_feature_extraction.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bova17CEnDCV"
   },
   "source": [
    "### Install required packages\n",
    "\n",
    "You should install the following packages by running the corresponding cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xPGEAL2nnDCX"
   },
   "outputs": [],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6A32uib4nDCX"
   },
   "source": [
    "If you experience issues with librosa because of numpy, try the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m_JO6SOXnDCX"
   },
   "outputs": [],
   "source": [
    "#!pip uninstall numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ce5XbYVknDCa"
   },
   "outputs": [],
   "source": [
    "#!pip uninstall numpy==1.20.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzm5VAXXnDCa"
   },
   "source": [
    "### Download and load audio files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_7g3Zz8nDCb"
   },
   "source": [
    "Let's download some audio files to work with. They are kick drum and snare drum samples, and each audio file contains one drum hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XglnAdsgnDCc",
    "outputId": "4a758321-62ce-4369-c493-39690bfae7c1"
   },
   "outputs": [],
   "source": [
    "!wget https://iie.fing.edu.uy/~rocamora/downloads/tmp/drum_samples.zip\n",
    "!unzip drum_samples.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZmF2CbinDCc"
   },
   "source": [
    "Now we load the audio signals of each class into two different lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bXf8T8wDnDCd"
   },
   "outputs": [],
   "source": [
    "kick_signals = [\n",
    "    librosa.load(str(p))[0] for p in Path().glob('drum_samples/train/kick_*.mp3')\n",
    "]\n",
    "snare_signals = [\n",
    "    librosa.load(str(p))[0] for p in Path().glob('drum_samples/train/snare_*.mp3')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZxis2R0oeop"
   },
   "source": [
    "Let's check the number of files of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oLYG9pOFnDCe",
    "outputId": "60307610-9dbc-4ab4-d254-a1422dd88313"
   },
   "outputs": [],
   "source": [
    "n_kick = len(kick_signals)\n",
    "print(n_kick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mtae0ejDnDCe",
    "outputId": "713ab054-e125-452c-8a4f-b8f7754df383"
   },
   "outputs": [],
   "source": [
    "n_snare = len(snare_signals)\n",
    "print(n_snare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1BhuX8AnDCe"
   },
   "source": [
    "We now display some of the kick drum signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "1CgFHA7UnDCf",
    "outputId": "ad9a399e-1165-4803-bcb6-abd0a8b5b2d2"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "for i, x in enumerate(kick_signals[:10]):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    librosa.display.waveshow(x[:10000])\n",
    "    plt.ylim(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgxKwcpinDCf"
   },
   "source": [
    "And some of the  snare drum signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 567
    },
    "id": "K0Wzn7tdnDCg",
    "outputId": "511fd93a-f19f-4793-820a-b5d2790d941c"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "for i, x in enumerate(snare_signals[:10]):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    librosa.display.waveshow(x[:10000])\n",
    "    plt.ylim(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLnDNphWsCAU"
   },
   "source": [
    "We can listen to some of the audio signals. Recall that `librosa` resamples audio to `fs=22050` by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 61
    },
    "id": "-dY9A8ENrxzb",
    "outputId": "845338e1-9f17-471d-b219-604b5ac9c3f5"
   },
   "outputs": [],
   "source": [
    "ipd.display(ipd.Audio(snare_signals[2], rate=22050))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 61
    },
    "id": "aGVbAa67szm1",
    "outputId": "c80b4e46-ec0b-4bec-dd8f-5bb15e2bc722"
   },
   "outputs": [],
   "source": [
    "ipd.display(ipd.Audio(kick_signals[10], rate=22050))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "SAasI7YJnDCg"
   },
   "source": [
    "### Part 1. Computing features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-BIsrQ-nDCg"
   },
   "source": [
    "The following is a simple function that constructs a two-dimensional feature vector from a signal.\n",
    "\n",
    "Add the code needed to compute some relevant features to be able to distinguish between the two classes.\n",
    "\n",
    "You should get only **one number for each feature**, so try to combine short-time feature values in a proper way (**temporal integration**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RnBIlAr6nDCg"
   },
   "outputs": [],
   "source": [
    "def extract_features(signal):\n",
    "    return [\n",
    "        # compute feature 1,\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "\n",
    "        # compute feature 2,\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bsKLWQZRnDCh"
   },
   "source": [
    "If we want to aggregate all of the feature vectors among signals in a collection, we can use a list comprehension as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lh2ZlqJ8nDCh",
    "outputId": "f7772cef-e885-47e6-bafc-56cee9207703"
   },
   "outputs": [],
   "source": [
    "kick_features = np.array([extract_features(x) for x in kick_signals])\n",
    "snare_features = np.array([extract_features(x) for x in snare_signals])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOEmI5_zuQXx"
   },
   "source": [
    "### Part 2. Visualizing features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyBGoUvhnDCi"
   },
   "source": [
    "In order to visualize the differences in the features values we can plot separate histograms for each of the classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "g9W6iTcLnDCi",
    "outputId": "34ca232f-13d9-408c-9537-b7e654a6deab"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "plt.hist(kick_features[:,0], color='b', alpha=0.5, bins=20)\n",
    "plt.hist(snare_features[:,0], color='r', alpha=0.5, bins=20)\n",
    "plt.legend(('kicks', 'snares'))\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "qEoESQ8JnDCi",
    "outputId": "ebaf8d4c-257d-4fc0-bbd0-dae20db31263"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "plt.hist(kick_features[:,1], color='b', bins=30, alpha=0.6)\n",
    "plt.hist(snare_features[:,1], color='r', bins=30, alpha=0.6)\n",
    "plt.legend(('kicks', 'snares'))\n",
    "plt.xlabel('Feature 2')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibD1yFBjnDCj"
   },
   "source": [
    "### Part 3. Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lU-TnqvznDCj"
   },
   "source": [
    " The two features we computed before are expressed using different units, so they can take very different values. This discrepancy can pose problems when performing classification later. Therefore, we will normalize each feature vector to a common range and store the normalization parameters for later use.  \n",
    "\n",
    "Many techniques exist for scaling your features. For now, we'll use [`sklearn.preprocessing.MinMaxScaler`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html).  `MinMaxScaler` returns an array of scaled values such that each feature dimension is in the range -1 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPw47f-XnDCj"
   },
   "source": [
    "Let's concatenate all of our feature vectors into one *feature table*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YPsfphKLnDCl",
    "outputId": "7bd564fd-fe8b-4068-cce2-894697859ffb"
   },
   "outputs": [],
   "source": [
    "feature_table = np.vstack((kick_features, snare_features))\n",
    "print(feature_table.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jh9nVI1szn-z"
   },
   "source": [
    "You can check the minimum and maximim values of the features before scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Vqk5XrWzS_L",
    "outputId": "a0569358-b1ac-4e65-ded7-299b92d78d37"
   },
   "outputs": [],
   "source": [
    "print(feature_table.min(axis=0))\n",
    "print(feature_table.max(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z2Wp-ufRnDCl"
   },
   "source": [
    "Scale each feature dimension to be in the range -1 to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YPReqf0WnDCl"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# scaled_features =\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vs_BGQYn0o0f"
   },
   "source": [
    "Now check that the features were actually scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q7YFGY780w6G",
    "outputId": "32ccac83-5623-4cdf-cced-dc7171365dcf"
   },
   "outputs": [],
   "source": [
    "print(scaled_features.min(axis=0))\n",
    "print(scaled_features.max(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaAd6z-AnDCl"
   },
   "source": [
    "Plot the scaled features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "PDiXZn3_nDCl",
    "outputId": "de307b70-ac39-4625-e46a-d9bca0d0f747"
   },
   "outputs": [],
   "source": [
    "plt.scatter(scaled_features[:n_kick,0], scaled_features[:n_kick,1], c='b')\n",
    "plt.scatter(scaled_features[n_kick:,0], scaled_features[n_kick:,1], c='r')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqKaR-dc2yi0"
   },
   "source": [
    "### Part 4. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9O_sNKG119L"
   },
   "source": [
    "Compute different features, plot their values, and try to answer the following:\n",
    "\n",
    "1.   How can you do temporal integration?\n",
    "2.   Which features are most useful for discriminating between the classes?\n",
    "3.   Is it useful to combine features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBJDZD792KU_"
   },
   "source": [
    "\n",
    "#### YOUR RESPONSE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvICKqa03Gzj"
   },
   "source": [
    "Decide on the two most useful features for discriminating between classes and try to justify the rationale behind it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIvQYdDN3ig2"
   },
   "source": [
    "#### YOUR RESPONSE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
